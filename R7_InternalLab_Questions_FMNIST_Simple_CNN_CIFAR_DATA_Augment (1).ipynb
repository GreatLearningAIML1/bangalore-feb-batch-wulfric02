{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyfMmMnPJjvn",
        "colab_type": "text"
      },
      "source": [
        "## Train a simple convnet on the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjcGOJhcJjvp",
        "colab_type": "text"
      },
      "source": [
        "In this, we will see how to deal with image data and train a convnet for image classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR0Pl2XjJjvq",
        "colab_type": "text"
      },
      "source": [
        "### Load the  `fashion_mnist`  dataset\n",
        "\n",
        "** Use keras.datasets to load the dataset **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l77UUnio5bsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense,Dropout,Activation,Flatten\n",
        "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr75v_UYJjvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTI42-0qJjvw",
        "colab_type": "text"
      },
      "source": [
        "### Find no.of samples are there in training and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2sf67VoJjvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fcc05ff-f417-4e77-e9fa-1e993471b576"
      },
      "source": [
        "x_train.shape\n",
        "# 60000 samples are available in train "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qD-JcPB3PhK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7ed468e-1d7f-4a5c-a859-acec9cf75ba7"
      },
      "source": [
        "x_test.shape\n",
        "# 10000 samples are available in test "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zewyDcBlJjv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WytT2eRnJjv4",
        "colab_type": "text"
      },
      "source": [
        "### Find dimensions of an image in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XycQGBSGJjv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ce9bdd0-427e-49f2-9a28-201f9e25a58a"
      },
      "source": [
        "x_train[0].shape\n",
        "\n",
        "# 28x28 is the dimension"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAKW4S2E4qDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u,counts = np.unique(y_train, return_counts=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9o3Aw6L6ArA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9428c6e6-356a-455e-c225-5091a637c34a"
      },
      "source": [
        "counts"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jtdZ7RqJjv8",
        "colab_type": "text"
      },
      "source": [
        "### Convert train and test labels to one hot vectors\n",
        "\n",
        "** check `keras.utils.to_categorical()` **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAD3q5I6Jjv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ytrain = tf.keras.utils.to_categorical(y_train, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgHSCXy3JjwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Ytest = tf.keras.utils.to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO5BRBzBJjwD",
        "colab_type": "text"
      },
      "source": [
        "### Normalize both the train and test image data from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fUQpMHxJjwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Okwo_SB5JjwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5-DwgrJjwM",
        "colab_type": "text"
      },
      "source": [
        "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPGVQ-JJJjwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_train=x_train.reshape(x_train.shape[0],28,28,1).astype('float32')\n",
        "x_test=x_test.reshape(x_test.shape[0],28,28,1).astype('float32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVhRBqsc8ISh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRRTJq8JjwQ",
        "colab_type": "text"
      },
      "source": [
        "### Import the necessary layers from keras to build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWTZYnKSJjwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C18AoS7eJjwU",
        "colab_type": "text"
      },
      "source": [
        "### Build a model \n",
        "\n",
        "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DORCLgSwJjwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "dc9d8f22-3feb-4e4e-f185-20ab3b62ba1a"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3),input_shape=(28,28,1),activation='relu'))\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "model.fit(x_train,Ytrain,epochs=10,verbose=1,validation_data=(x_test,Ytest),callbacks=[cb])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 9s 149us/sample - loss: 0.3745 - acc: 0.8649 - val_loss: 0.3070 - val_acc: 0.8918\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.2356 - acc: 0.9135 - val_loss: 0.2553 - val_acc: 0.9052\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 0.1717 - acc: 0.9356 - val_loss: 0.2675 - val_acc: 0.9059\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 0.1212 - acc: 0.9555 - val_loss: 0.2611 - val_acc: 0.9130\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.0823 - acc: 0.9695 - val_loss: 0.3187 - val_acc: 0.9076\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.0549 - acc: 0.9800 - val_loss: 0.3543 - val_acc: 0.9079\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 137us/sample - loss: 0.0398 - acc: 0.9855 - val_loss: 0.3705 - val_acc: 0.9107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4a800df198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju69vKdIJjwX",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2hAP94vJjwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "6f2f3f33-ee17-4705-fb32-936506410f0e"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3),input_shape=(28,28,1),activation='relu'))\n",
        "model.add(tf.keras.layers.Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "model.fit(x_train,Ytrain,epochs=10,verbose=1,validation_data=(x_test,Ytest),callbacks=[cb])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.3911 - acc: 0.8586 - val_loss: 0.3100 - val_acc: 0.8878\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.2628 - acc: 0.9042 - val_loss: 0.2558 - val_acc: 0.9052\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.2131 - acc: 0.9214 - val_loss: 0.2280 - val_acc: 0.9172\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.1803 - acc: 0.9323 - val_loss: 0.2178 - val_acc: 0.9209\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.1522 - acc: 0.9425 - val_loss: 0.2287 - val_acc: 0.9206\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.1289 - acc: 0.9506 - val_loss: 0.2288 - val_acc: 0.9201\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.1095 - acc: 0.9583 - val_loss: 0.2417 - val_acc: 0.9244\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0945 - acc: 0.9640 - val_loss: 0.2347 - val_acc: 0.9272\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0800 - acc: 0.9692 - val_loss: 0.2501 - val_acc: 0.9263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4a813f1898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGTA3bfEJjwa",
        "colab_type": "text"
      },
      "source": [
        "### Now, to the above model, lets add Data Augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6gX8n5SJjwb",
        "colab_type": "text"
      },
      "source": [
        "### Import the ImageDataGenrator from keras and fit the training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbz4uHBuJjwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl-8dOo7Jjwf",
        "colab_type": "text"
      },
      "source": [
        "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DpI1_McYJjwg",
        "colab_type": "code",
        "outputId": "814a8240-73da-4782-944b-30de71a37638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAABcCAYAAABz9T77AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmPl5yE8Jjwm",
        "colab_type": "text"
      },
      "source": [
        "### Run the above model using fit_generator()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ZnDdJYJjwn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb494263-2307-4e4d-a338-6e270dedcd91"
      },
      "source": [
        "model.fit_generator(datagen.flow(x_train, Ytrain, batch_size=32),\n",
        "                    steps_per_epoch=len(x_train) / 32, epochs=50,validation_data=(x_test,Ytest))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.7438 - acc: 0.7245 - val_loss: 0.3541 - val_acc: 0.8758\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.5502 - acc: 0.7952 - val_loss: 0.3564 - val_acc: 0.8720\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.5033 - acc: 0.8141 - val_loss: 0.3338 - val_acc: 0.8795\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4696 - acc: 0.8252 - val_loss: 0.3308 - val_acc: 0.8797\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.4497 - acc: 0.8326 - val_loss: 0.3217 - val_acc: 0.8864\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.4323 - acc: 0.8394 - val_loss: 0.3260 - val_acc: 0.8879\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.4204 - acc: 0.8431 - val_loss: 0.3070 - val_acc: 0.8906\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.4137 - acc: 0.8451 - val_loss: 0.3268 - val_acc: 0.8816\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4040 - acc: 0.8501 - val_loss: 0.3592 - val_acc: 0.8679\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.4026 - acc: 0.8505 - val_loss: 0.3507 - val_acc: 0.8767\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3954 - acc: 0.8542 - val_loss: 0.3221 - val_acc: 0.8881\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3879 - acc: 0.8565 - val_loss: 0.3386 - val_acc: 0.8780\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3822 - acc: 0.8580 - val_loss: 0.3279 - val_acc: 0.8846\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3802 - acc: 0.8590 - val_loss: 0.3214 - val_acc: 0.8862\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3753 - acc: 0.8614 - val_loss: 0.3227 - val_acc: 0.8850\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3733 - acc: 0.8609 - val_loss: 0.3195 - val_acc: 0.8877\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3674 - acc: 0.8634 - val_loss: 0.3159 - val_acc: 0.8927\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3627 - acc: 0.8667 - val_loss: 0.3129 - val_acc: 0.8907\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3606 - acc: 0.8666 - val_loss: 0.3040 - val_acc: 0.8955\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3625 - acc: 0.8655 - val_loss: 0.3029 - val_acc: 0.8928\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3576 - acc: 0.8692 - val_loss: 0.3041 - val_acc: 0.8923\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3533 - acc: 0.8681 - val_loss: 0.3032 - val_acc: 0.8926\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3510 - acc: 0.8705 - val_loss: 0.3245 - val_acc: 0.8851\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3486 - acc: 0.8709 - val_loss: 0.3106 - val_acc: 0.8943\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3504 - acc: 0.8705 - val_loss: 0.3030 - val_acc: 0.8924\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3469 - acc: 0.8716 - val_loss: 0.2987 - val_acc: 0.8956\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3464 - acc: 0.8720 - val_loss: 0.3244 - val_acc: 0.8884\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3433 - acc: 0.8735 - val_loss: 0.3133 - val_acc: 0.8920\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3422 - acc: 0.8742 - val_loss: 0.2972 - val_acc: 0.8936\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3407 - acc: 0.8739 - val_loss: 0.3057 - val_acc: 0.8950\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3421 - acc: 0.8755 - val_loss: 0.3036 - val_acc: 0.8940\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3372 - acc: 0.8749 - val_loss: 0.3023 - val_acc: 0.8910\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3371 - acc: 0.8765 - val_loss: 0.3156 - val_acc: 0.8898\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3340 - acc: 0.8770 - val_loss: 0.3319 - val_acc: 0.8888\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3340 - acc: 0.8774 - val_loss: 0.3036 - val_acc: 0.8950\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3360 - acc: 0.8774 - val_loss: 0.3058 - val_acc: 0.8915\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3328 - acc: 0.8774 - val_loss: 0.3037 - val_acc: 0.8966\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3313 - acc: 0.8783 - val_loss: 0.3043 - val_acc: 0.8962\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3322 - acc: 0.8767 - val_loss: 0.2986 - val_acc: 0.8978\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3306 - acc: 0.8778 - val_loss: 0.3214 - val_acc: 0.8952\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3293 - acc: 0.8793 - val_loss: 0.2983 - val_acc: 0.8969\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3270 - acc: 0.8793 - val_loss: 0.2861 - val_acc: 0.8999\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3272 - acc: 0.8794 - val_loss: 0.3131 - val_acc: 0.8896\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3252 - acc: 0.8811 - val_loss: 0.2974 - val_acc: 0.8949\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3249 - acc: 0.8807 - val_loss: 0.3108 - val_acc: 0.8923\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3257 - acc: 0.8789 - val_loss: 0.3104 - val_acc: 0.8941\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3226 - acc: 0.8800 - val_loss: 0.3010 - val_acc: 0.8939\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3244 - acc: 0.8810 - val_loss: 0.3146 - val_acc: 0.8939\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.3246 - acc: 0.8804 - val_loss: 0.3072 - val_acc: 0.8936\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 20s 10ms/step - loss: 0.3224 - acc: 0.8818 - val_loss: 0.3168 - val_acc: 0.8923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4a80605198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQQW5iOJjwq",
        "colab_type": "text"
      },
      "source": [
        "###  Report the final train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1SrtBEPJjwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Accuracy - 88%\n",
        "# Validation Accuracy - 89%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBwVWNQC2qZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KXqmUDW2rM1",
        "colab_type": "text"
      },
      "source": [
        "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mja6OgQ3L18",
        "colab_type": "text"
      },
      "source": [
        "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HzVTPUM3WZJ",
        "colab_type": "text"
      },
      "source": [
        "### **Import neessary libraries for data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPM558TX4KMb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6hicLwP4SqY",
        "colab_type": "text"
      },
      "source": [
        "### **Load CIFAR10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ1WzrXd4WNk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "55cb4750-4e4c-4603-be0b-d6d7164628cc"
      },
      "source": [
        "(xtrain, ytrain), (xtest, ytest) = cifar10.load_data()\n",
        "print('x_train shape:', xtrain.shape)\n",
        "print(xtrain.shape[0], 'train samples')\n",
        "print(xtest.shape[0], 'test samples')\n",
        "\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJL8GXNqHk_I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12fdc756-2dde-451f-8c12-fee4b5acd49d"
      },
      "source": [
        "xtrain.dtype"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0215S5KjIeAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain = (xtrain/255).astype('float32')\n",
        "xtest = (xtest/255).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Pht1ggHuiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ytrain = keras.utils.to_categorical(ytrain, num_classes=10)\n",
        "ytest = keras.utils.to_categorical(ytest, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n28ccU6Hp6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3vYYhK4W0u",
        "colab_type": "text"
      },
      "source": [
        "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJbekTKi4cmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cifarDatagen = ImageDataGenerator(rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "cifarDatagen.fit(xtrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-SLtUhC4dK2",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare/fit the generator.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSw8Bv2_4hb0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6169e4d9-a132-401b-f06c-875f4e6c522d"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=xtrain.shape[1:],activation='relu'))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(datagen.flow(xtrain, ytrain, batch_size=32),\n",
        "                    steps_per_epoch=len(xtrain) / 32, epochs=100,validation_data=(xtest,ytest))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 1.7636 - acc: 0.3435 - val_loss: 1.5232 - val_acc: 0.4371\n",
            "Epoch 2/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 1.4786 - acc: 0.4598 - val_loss: 1.2403 - val_acc: 0.5447\n",
            "Epoch 3/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 1.3712 - acc: 0.5033 - val_loss: 1.2272 - val_acc: 0.5638\n",
            "Epoch 4/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 1.2990 - acc: 0.5320 - val_loss: 1.1375 - val_acc: 0.5865\n",
            "Epoch 5/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 1.2476 - acc: 0.5544 - val_loss: 1.0700 - val_acc: 0.6142\n",
            "Epoch 6/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 1.2111 - acc: 0.5705 - val_loss: 1.1149 - val_acc: 0.6056\n",
            "Epoch 7/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 1.1842 - acc: 0.5765 - val_loss: 0.9849 - val_acc: 0.6525\n",
            "Epoch 8/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 1.1600 - acc: 0.5864 - val_loss: 1.0698 - val_acc: 0.6201\n",
            "Epoch 9/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 1.1387 - acc: 0.5952 - val_loss: 0.9870 - val_acc: 0.6546\n",
            "Epoch 10/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 1.1278 - acc: 0.5981 - val_loss: 0.9774 - val_acc: 0.6567\n",
            "Epoch 11/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 1.1062 - acc: 0.6071 - val_loss: 1.0052 - val_acc: 0.6443\n",
            "Epoch 12/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 1.0896 - acc: 0.6146 - val_loss: 1.0399 - val_acc: 0.6409\n",
            "Epoch 13/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 1.0784 - acc: 0.6175 - val_loss: 0.9286 - val_acc: 0.6749\n",
            "Epoch 14/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 1.0693 - acc: 0.6221 - val_loss: 0.9782 - val_acc: 0.6667\n",
            "Epoch 15/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 1.0635 - acc: 0.6244 - val_loss: 0.9091 - val_acc: 0.6804\n",
            "Epoch 16/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 1.0527 - acc: 0.6281 - val_loss: 0.8952 - val_acc: 0.6822\n",
            "Epoch 17/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 1.0455 - acc: 0.6319 - val_loss: 0.9069 - val_acc: 0.6797\n",
            "Epoch 18/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 1.0376 - acc: 0.6357 - val_loss: 0.8720 - val_acc: 0.6981\n",
            "Epoch 19/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 1.0270 - acc: 0.6408 - val_loss: 0.8779 - val_acc: 0.6900\n",
            "Epoch 20/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 1.0205 - acc: 0.6437 - val_loss: 0.8853 - val_acc: 0.6925\n",
            "Epoch 21/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 1.0139 - acc: 0.6438 - val_loss: 0.8111 - val_acc: 0.7175\n",
            "Epoch 22/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 1.0158 - acc: 0.6443 - val_loss: 0.8960 - val_acc: 0.6859\n",
            "Epoch 23/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 1.0128 - acc: 0.6452 - val_loss: 0.8144 - val_acc: 0.7179\n",
            "Epoch 24/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 1.0013 - acc: 0.6504 - val_loss: 0.8653 - val_acc: 0.7006\n",
            "Epoch 25/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 1.0015 - acc: 0.6486 - val_loss: 0.9106 - val_acc: 0.6895\n",
            "Epoch 26/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9907 - acc: 0.6545 - val_loss: 0.9277 - val_acc: 0.6869\n",
            "Epoch 27/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9924 - acc: 0.6520 - val_loss: 0.8402 - val_acc: 0.7108\n",
            "Epoch 28/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9898 - acc: 0.6552 - val_loss: 0.8538 - val_acc: 0.7062\n",
            "Epoch 29/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9856 - acc: 0.6547 - val_loss: 0.8591 - val_acc: 0.7060\n",
            "Epoch 30/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9792 - acc: 0.6617 - val_loss: 0.9601 - val_acc: 0.6760\n",
            "Epoch 31/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9748 - acc: 0.6615 - val_loss: 0.8175 - val_acc: 0.7192\n",
            "Epoch 32/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9819 - acc: 0.6579 - val_loss: 0.8181 - val_acc: 0.7190\n",
            "Epoch 33/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9688 - acc: 0.6630 - val_loss: 0.7958 - val_acc: 0.7217\n",
            "Epoch 34/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9715 - acc: 0.6623 - val_loss: 0.8138 - val_acc: 0.7209\n",
            "Epoch 35/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9640 - acc: 0.6636 - val_loss: 0.8044 - val_acc: 0.7227\n",
            "Epoch 36/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9664 - acc: 0.6632 - val_loss: 0.7980 - val_acc: 0.7275\n",
            "Epoch 37/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9641 - acc: 0.6657 - val_loss: 0.7805 - val_acc: 0.7296\n",
            "Epoch 38/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9577 - acc: 0.6685 - val_loss: 0.8894 - val_acc: 0.6983\n",
            "Epoch 39/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9629 - acc: 0.6661 - val_loss: 0.9348 - val_acc: 0.6872\n",
            "Epoch 40/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9561 - acc: 0.6690 - val_loss: 0.8235 - val_acc: 0.7174\n",
            "Epoch 41/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9492 - acc: 0.6717 - val_loss: 0.7937 - val_acc: 0.7272\n",
            "Epoch 42/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9441 - acc: 0.6742 - val_loss: 0.8203 - val_acc: 0.7245\n",
            "Epoch 43/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9456 - acc: 0.6730 - val_loss: 0.7826 - val_acc: 0.7289\n",
            "Epoch 44/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9491 - acc: 0.6706 - val_loss: 0.8629 - val_acc: 0.7036\n",
            "Epoch 45/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9481 - acc: 0.6718 - val_loss: 0.8185 - val_acc: 0.7202\n",
            "Epoch 46/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9448 - acc: 0.6744 - val_loss: 0.9048 - val_acc: 0.6894\n",
            "Epoch 47/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9384 - acc: 0.6761 - val_loss: 0.8228 - val_acc: 0.7208\n",
            "Epoch 48/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9378 - acc: 0.6735 - val_loss: 0.8136 - val_acc: 0.7246\n",
            "Epoch 49/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9419 - acc: 0.6732 - val_loss: 0.8200 - val_acc: 0.7154\n",
            "Epoch 50/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9393 - acc: 0.6750 - val_loss: 0.7797 - val_acc: 0.7327\n",
            "Epoch 51/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9406 - acc: 0.6761 - val_loss: 0.7825 - val_acc: 0.7346\n",
            "Epoch 52/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9302 - acc: 0.6771 - val_loss: 0.8448 - val_acc: 0.7127\n",
            "Epoch 53/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9328 - acc: 0.6776 - val_loss: 0.9684 - val_acc: 0.6743\n",
            "Epoch 54/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9355 - acc: 0.6772 - val_loss: 0.8129 - val_acc: 0.7258\n",
            "Epoch 55/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9301 - acc: 0.6787 - val_loss: 0.7740 - val_acc: 0.7387\n",
            "Epoch 56/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9384 - acc: 0.6741 - val_loss: 0.8021 - val_acc: 0.7326\n",
            "Epoch 57/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9233 - acc: 0.6791 - val_loss: 0.8654 - val_acc: 0.7152\n",
            "Epoch 58/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9333 - acc: 0.6772 - val_loss: 0.8057 - val_acc: 0.7230\n",
            "Epoch 59/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9292 - acc: 0.6780 - val_loss: 0.8560 - val_acc: 0.7090\n",
            "Epoch 60/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9241 - acc: 0.6816 - val_loss: 0.8782 - val_acc: 0.7034\n",
            "Epoch 61/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9267 - acc: 0.6795 - val_loss: 0.7725 - val_acc: 0.7383\n",
            "Epoch 62/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9242 - acc: 0.6801 - val_loss: 0.7700 - val_acc: 0.7367\n",
            "Epoch 63/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9208 - acc: 0.6803 - val_loss: 0.8479 - val_acc: 0.7092\n",
            "Epoch 64/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9188 - acc: 0.6814 - val_loss: 0.8732 - val_acc: 0.7147\n",
            "Epoch 65/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9284 - acc: 0.6791 - val_loss: 0.8476 - val_acc: 0.7193\n",
            "Epoch 66/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9233 - acc: 0.6808 - val_loss: 0.7933 - val_acc: 0.7253\n",
            "Epoch 67/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9308 - acc: 0.6822 - val_loss: 0.7790 - val_acc: 0.7372\n",
            "Epoch 68/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9184 - acc: 0.6836 - val_loss: 0.8188 - val_acc: 0.7273\n",
            "Epoch 69/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9250 - acc: 0.6801 - val_loss: 0.8302 - val_acc: 0.7145\n",
            "Epoch 70/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9080 - acc: 0.6885 - val_loss: 0.8080 - val_acc: 0.7336\n",
            "Epoch 71/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9210 - acc: 0.6819 - val_loss: 0.8668 - val_acc: 0.7288\n",
            "Epoch 72/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9177 - acc: 0.6851 - val_loss: 0.7192 - val_acc: 0.7542\n",
            "Epoch 73/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9188 - acc: 0.6833 - val_loss: 0.7821 - val_acc: 0.7308\n",
            "Epoch 74/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9206 - acc: 0.6822 - val_loss: 0.8382 - val_acc: 0.7143\n",
            "Epoch 75/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9156 - acc: 0.6844 - val_loss: 0.7959 - val_acc: 0.7300\n",
            "Epoch 76/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9162 - acc: 0.6838 - val_loss: 0.8036 - val_acc: 0.7274\n",
            "Epoch 77/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9171 - acc: 0.6842 - val_loss: 0.8970 - val_acc: 0.7173\n",
            "Epoch 78/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9194 - acc: 0.6837 - val_loss: 0.7634 - val_acc: 0.7455\n",
            "Epoch 79/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9170 - acc: 0.6843 - val_loss: 0.8007 - val_acc: 0.7295\n",
            "Epoch 80/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9173 - acc: 0.6830 - val_loss: 0.8712 - val_acc: 0.7034\n",
            "Epoch 81/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9097 - acc: 0.6871 - val_loss: 0.7412 - val_acc: 0.7540\n",
            "Epoch 82/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9120 - acc: 0.6841 - val_loss: 0.7845 - val_acc: 0.7395\n",
            "Epoch 83/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9134 - acc: 0.6845 - val_loss: 0.7790 - val_acc: 0.7379\n",
            "Epoch 84/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9146 - acc: 0.6824 - val_loss: 0.7722 - val_acc: 0.7461\n",
            "Epoch 85/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9089 - acc: 0.6881 - val_loss: 0.7791 - val_acc: 0.7433\n",
            "Epoch 86/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9073 - acc: 0.6894 - val_loss: 0.8440 - val_acc: 0.7231\n",
            "Epoch 87/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9120 - acc: 0.6888 - val_loss: 0.8081 - val_acc: 0.7318\n",
            "Epoch 88/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9025 - acc: 0.6906 - val_loss: 0.8204 - val_acc: 0.7229\n",
            "Epoch 89/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9113 - acc: 0.6879 - val_loss: 0.8159 - val_acc: 0.7285\n",
            "Epoch 90/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9072 - acc: 0.6879 - val_loss: 0.7888 - val_acc: 0.7310\n",
            "Epoch 91/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9046 - acc: 0.6892 - val_loss: 0.8503 - val_acc: 0.7116\n",
            "Epoch 92/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9043 - acc: 0.6889 - val_loss: 0.8105 - val_acc: 0.7247\n",
            "Epoch 93/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9012 - acc: 0.6906 - val_loss: 0.8157 - val_acc: 0.7270\n",
            "Epoch 94/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9101 - acc: 0.6885 - val_loss: 0.8391 - val_acc: 0.7294\n",
            "Epoch 95/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9089 - acc: 0.6867 - val_loss: 0.8304 - val_acc: 0.7222\n",
            "Epoch 96/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9066 - acc: 0.6869 - val_loss: 0.8272 - val_acc: 0.7217\n",
            "Epoch 97/100\n",
            "1563/1562 [==============================] - 29s 19ms/step - loss: 0.9042 - acc: 0.6879 - val_loss: 0.7522 - val_acc: 0.7481\n",
            "Epoch 98/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9094 - acc: 0.6876 - val_loss: 0.7514 - val_acc: 0.7447\n",
            "Epoch 99/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9021 - acc: 0.6889 - val_loss: 0.7976 - val_acc: 0.7353\n",
            "Epoch 100/100\n",
            "1563/1562 [==============================] - 30s 19ms/step - loss: 0.9124 - acc: 0.6859 - val_loss: 0.7512 - val_acc: 0.7453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4a0ae43908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQMOkHN_ZYAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training accuracy - 68%\n",
        "# Validation accuracy - 74%"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYyF-P8O4jQ8",
        "colab_type": "text"
      },
      "source": [
        "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXug4z234mwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "88038fdc-414d-441e-f3f3-dccaaf2cde4f"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "gen = datagen.flow(xtrain[0:1], batch_size=1)\n",
        "for i in range(1, 6):\n",
        "    plt.subplot(1,5,i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(gen.next().squeeze())\n",
        "    plt.plot()\n",
        "plt.show()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAABcCAYAAAB3AO7GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMDAwuKX4rz1kKG79d5n3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcioRTwpLbJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}